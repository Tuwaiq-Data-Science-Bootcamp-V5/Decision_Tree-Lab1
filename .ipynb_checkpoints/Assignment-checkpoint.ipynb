{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b891750",
   "metadata": {},
   "source": [
    "## 1. Credit card applications\n",
    "<p>Commercial banks receive <em>a lot</em> of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this notebook, we will build an automatic credit card approval predictor using machine learning techniques, just like the real banks do.</p>\n",
    "<p><img src=\"https://assets.datacamp.com/production/project_558/img/credit_card.jpg\" alt=\"Credit card being held in hand\"></p>\n",
    "<p>We'll use the <a href=\"http://archive.ics.uci.edu/ml/datasets/credit+approval\">Credit Card Approval dataset</a> from the UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d13d18",
   "metadata": {},
   "source": [
    "## 2. Import Pandas\n",
    "\n",
    "1. Import pandas and alias it as pd\n",
    "2. Load the dataset cc_approvals.data into a cc_apps dataframe.\n",
    "    - Set the header argument to None.\n",
    "3. Print the first five rows.\n",
    "4. Drop the columns 11 and 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2477ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e269a3c",
   "metadata": {},
   "source": [
    "## 3. Explore the dataset\n",
    "\n",
    "1. Print the basic statistics.\n",
    "2. Print the information of the dataset.\n",
    "3. Print the last 17 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b265c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac6804f9",
   "metadata": {},
   "source": [
    "## 4. Train Test Split\n",
    "\n",
    "Do not split the dataset into X and y, just split the original dataset.\n",
    "\n",
    "random_state=42\n",
    "\n",
    "test_size=0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e541590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47dc98df",
   "metadata": {},
   "source": [
    "## 5. Handling Missing Values\n",
    "\n",
    "Convert any '?' to a NaN value from both training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa9cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e17357e6",
   "metadata": {},
   "source": [
    "## 6. Handling Missing Values\n",
    "\n",
    "Impute the numerical data for both training and testing sets with mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecdbf72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cef56745",
   "metadata": {},
   "source": [
    "## 7. Handling Missing Values\n",
    "\n",
    "Impute the categorical data for both training and testing sets with mode value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b2094e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "767929aa",
   "metadata": {},
   "source": [
    "## 8. Encoding\n",
    "\n",
    "The columns 0, 3, 4, 5, 6, 8, 9, and 12 are categorical, there are several methods we can use to encode the categorical columns. One of the method called get_dummies().\n",
    "\n",
    "Use get_dummies() function to convert the categorical columns to a numerical columns (for training the machine learning algorithms).\n",
    "\n",
    "Do not forget to convert both training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c1eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39a7859a",
   "metadata": {},
   "source": [
    "## 9. Split into features and target\n",
    "\n",
    "X_train and y_train will take 462 rows.\n",
    "X_test and y_test will take 228 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6f8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60df8eb6",
   "metadata": {},
   "source": [
    "## 10. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adc20cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1dfc1ee",
   "metadata": {},
   "source": [
    "## 11. Train a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d8487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a4fe72d",
   "metadata": {},
   "source": [
    "## 12. Make predictions and evaluate the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc23d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2fd9a1c",
   "metadata": {},
   "source": [
    "## 13. Repeat the steps 11 and 12 for SVM, DT, and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065b484f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
